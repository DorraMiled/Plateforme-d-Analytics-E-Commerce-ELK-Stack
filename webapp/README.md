# üîß Backend - Flask REST API

API REST compl√®te pour la plateforme d'analytics e-commerce avec int√©gration ELK Stack, MongoDB et Redis.

## üìã Table des mati√®res

- [Technologies](#technologies)
- [Architecture](#architecture)
- [Endpoints API](#endpoints-api)
- [Installation](#installation)
- [Configuration](#configuration)
- [D√©veloppement](#d√©veloppement)
- [D√©ploiement](#d√©ploiement)

## üõ†Ô∏è Technologies

- **Framework**: Flask 3.0
- **WSGI Server**: Gunicorn
- **Database**: MongoDB 7.x
- **Cache**: Redis 7.x
- **Search Engine**: Elasticsearch 8.x
- **Data Processing**: Pandas, NumPy
- **HTTP Client**: Requests
- **CORS**: Flask-CORS

## üèóÔ∏è Architecture

```
webapp/
‚îú‚îÄ‚îÄ app.py                 # Application Flask principale
‚îú‚îÄ‚îÄ uploads/               # Dossier des fichiers upload√©s
‚îú‚îÄ‚îÄ requirements.txt       # D√©pendances Python
‚îî‚îÄ‚îÄ README.md             # Ce fichier
```

### Services int√©gr√©s

```
Flask API (port 8000)
    ‚Üì
‚îú‚îÄ‚îÄ MongoDB (port 27017)      # Stockage persistant
‚îú‚îÄ‚îÄ Redis (port 6379)         # Cache haute performance
‚îî‚îÄ‚îÄ Elasticsearch (port 9200) # Recherche et analytics
```

## üì° Endpoints API

### **System Endpoints**

#### `GET /`
**Description**: Status syst√®me et services connect√©s

**Response**:
```json
{
  "message": "E-commerce Flask Application",
  "status": "running",
  "timestamp": "2025-12-23T10:30:00",
  "services": {
    "mongodb": "connected",
    "redis": "connected",
    "elasticsearch": "connected"
  }
}
```

#### `GET /health`
**Description**: Health check endpoint

**Response**:
```json
{
  "status": "healthy",
  "timestamp": "2025-12-23T10:30:00"
}
```

#### `GET /api/services-status`
**Description**: √âtat d√©taill√© de tous les services

**Response**:
```json
{
  "mongodb": {
    "status": "connected",
    "collections": ["products", "orders", "searches"]
  },
  "redis": {
    "status": "connected",
    "dbsize": 42
  },
  "elasticsearch": {
    "status": "connected",
    "indices": ["ecommerce-logs-*"]
  }
}
```

---

### **MongoDB Endpoints**

#### `GET /api/products`
**Description**: Liste tous les produits

**Response**:
```json
{
  "count": 45,
  "products": [
    {
      "id": "1",
      "name": "Laptop HP",
      "price": 799.99,
      "category": "Electronics"
    }
  ]
}
```

#### `GET /api/orders`
**Description**: Liste toutes les commandes

**Response**:
```json
{
  "count": 100,
  "orders": [
    {
      "order_id": "ORD001",
      "customer": "John Doe",
      "total": 1299.99,
      "date": "2025-12-23"
    }
  ]
}
```

#### `POST /api/search/save`
**Description**: Sauvegarde une recherche

**Request Body**:
```json
{
  "query": "error",
  "level": "ERROR",
  "service": "payment-service",
  "timestamp": "2025-12-23T10:30:00"
}
```

#### `GET /api/search/history`
**Description**: Historique des recherches

**Response**:
```json
{
  "count": 10,
  "searches": [
    {
      "query": "error",
      "timestamp": "2025-12-23T10:30:00"
    }
  ]
}
```

---

### **Redis Endpoints**

#### `GET /api/cache/<key>`
**Description**: R√©cup√©rer une valeur du cache

**Response**:
```json
{
  "key": "user:123",
  "value": "John Doe",
  "ttl": 3600
}
```

#### `POST /api/cache`
**Description**: Cr√©er une entr√©e cache

**Request Body**:
```json
{
  "key": "user:123",
  "value": "John Doe",
  "ttl": 3600
}
```

#### `GET /api/cache/stats`
**Description**: Statistiques Redis

**Response**:
```json
{
  "dbsize": 42,
  "used_memory": "1.5M",
  "connected_clients": 3
}
```

---

### **Elasticsearch Endpoints**

#### `POST /api/search`
**Description**: Recherche full-text avec filtres

**Request Body**:
```json
{
  "query": "error",
  "level": "ERROR",
  "service": "payment-service",
  "start_date": "2025-12-01",
  "end_date": "2025-12-23",
  "page": 1,
  "size": 25
}
```

**Response**:
```json
{
  "total": 150,
  "page": 1,
  "size": 25,
  "results": [
    {
      "timestamp": "2025-12-23T10:30:00",
      "level": "ERROR",
      "service": "payment-service",
      "message": "Payment failed",
      "user": "user123"
    }
  ]
}
```

#### `GET /api/dashboard`
**Description**: M√©triques dashboard (KPIs + graphiques)

**Response**:
```json
{
  "total_logs": 132700,
  "logs_today": 1523,
  "error_logs": 245,
  "files_uploaded": 8,
  "by_level": [
    {"level": "INFO", "count": 85000},
    {"level": "ERROR", "count": 245}
  ],
  "by_day": [
    {"date": "2025-12-23", "count": 1523}
  ],
  "recent_logs": [...]
}
```

#### `GET /api/results`
**Description**: R√©sultats et analytics agr√©g√©s

**Response**:
```json
{
  "summary": {
    "total_revenue": 125000.50,
    "total_orders": 1500,
    "avg_order_value": 83.33,
    "unique_customers": 450
  },
  "by_country": [...],
  "top_products": [...],
  "over_time": [...]
}
```

#### `GET /api/export/csv`
**Description**: Export CSV avec filtres

**Query Parameters**:
- `q`: Query string
- `level`: Niveau de log
- `service`: Service
- `start_date`: Date d√©but
- `end_date`: Date fin

**Response**: Fichier CSV t√©l√©chargeable
```csv
Timestamp,Level,Service,Message,User
2025-12-23T10:30:00,ERROR,payment-service,Payment failed,user123
```

---

### **File Management**

#### `POST /api/upload`
**Description**: Upload fichier (CSV/JSON/TXT)

**Request**: `multipart/form-data`
- `file`: Fichier √† uploader (max 16MB)

**Response**:
```json
{
  "message": "File uploaded successfully",
  "filename": "logs_20251223.csv",
  "size": 1024000,
  "indexed": true,
  "documents_indexed": 1000
}
```

**Formats support√©s**:
- CSV (avec headers)
- JSON (array ou lignes)
- TXT (logs texte)

**Validation**:
- Taille max: 16 MB
- Extensions: .csv, .json, .txt
- Encoding: UTF-8

#### `GET /api/files`
**Description**: Liste fichiers upload√©s avec m√©tadonn√©es

**Response**:
```json
{
  "count": 8,
  "files": [
    {
      "filename": "logs_20251223.csv",
      "size": 1024000,
      "type": "text/csv",
      "upload_time": "2025-12-23T10:30:00"
    }
  ]
}
```

---

## üöÄ Installation

### Pr√©requis
- Python 3.9 ou sup√©rieur
- pip 21.x ou sup√©rieur
- MongoDB, Redis, Elasticsearch en cours d'ex√©cution

### Installation des d√©pendances
```bash
cd webapp
pip install -r requirements.txt
```

### D√©pendances principales
```txt
flask==3.0.0
flask-cors==4.0.0
pymongo==4.6.0
redis==5.0.1
elasticsearch==8.11.0
pandas==2.1.4
requests==2.31.0
```

---

## ‚öôÔ∏è Configuration

### Variables d'environnement
Cr√©er un fichier `.env`:
```bash
# MongoDB
MONGODB_URI=mongodb://admin:admin123@localhost:27017/ecommerce?authSource=admin

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379

# Elasticsearch
ELASTICSEARCH_HOST=http://localhost:9200

# Upload
UPLOAD_FOLDER=/app/uploads
MAX_CONTENT_LENGTH=16777216  # 16MB
```

### Configuration Flask
```python
# app.py
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
```

### CORS Configuration
```python
CORS(app, resources={
    r"/api/*": {
        "origins": "*",
        "methods": ["GET", "POST", "PUT", "DELETE", "OPTIONS"],
        "allow_headers": ["Content-Type", "Authorization"]
    }
})
```

---

## üíª D√©veloppement

### D√©marrer le serveur
```bash
cd webapp
python app.py
```

Serveur disponible sur: `http://localhost:8000`

### Mode debug
```python
if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8000, debug=True)
```

### Tests manuels
```bash
# Test status
curl http://localhost:8000/

# Test dashboard
curl http://localhost:8000/api/dashboard

# Test search
curl -X POST http://localhost:8000/api/search \
  -H "Content-Type: application/json" \
  -d '{"query":"error","level":"ERROR"}'

# Test upload
curl -X POST http://localhost:8000/api/upload \
  -F "file=@logs.csv"
```

---

## üìä Fonctionnalit√©s cl√©s

### 1. Upload et indexation
**Workflow**:
1. Validation fichier (type, taille)
2. Sauvegarde s√©curis√©e (`secure_filename`)
3. Parsing selon format (CSV ‚Üí Pandas, JSON ‚Üí dict)
4. Transformation des donn√©es
5. Indexation dans Elasticsearch
6. Stockage m√©tadonn√©es MongoDB

**Code**:
```python
@app.route('/api/upload', methods=['POST'])
def upload_file():
    file = request.files['file']
    filename = secure_filename(file.filename)
    filepath = os.path.join(UPLOAD_FOLDER, filename)
    file.save(filepath)
    
    # Index to Elasticsearch
    index_file_to_elasticsearch(filepath)
    
    return jsonify({'message': 'File uploaded successfully'})
```

### 2. Recherche avanc√©e
**Fonctionnalit√©s**:
- Full-text search (query_string)
- Filtres combinables (bool query)
- Range queries (dates)
- Pagination
- Tri personnalis√©

**Code**:
```python
must = []
if query:
    must.append({"query_string": {"query": f"*{query}*"}})
if level:
    must.append({"match": {"Level": level}})
if start_date or end_date:
    must.append({"range": {"@timestamp": {...}}})

search_body = {
    "query": {"bool": {"must": must}},
    "size": size,
    "from": (page - 1) * size
}
```

### 3. Export CSV
**Fonctionnalit√©s**:
- G√©n√©ration en m√©moire (`io.StringIO`)
- Headers personnalis√©s
- Support 3 formats de documents
- Nom fichier avec timestamp
- Content-Disposition attachment

**Code**:
```python
output = io.StringIO()
csv_writer = csv.writer(output)
csv_writer.writerow(['Timestamp', 'Level', 'Service', 'Message', 'User'])

for hit in result['hits']['hits']:
    row = [source.get('timestamp'), ...]
    csv_writer.writerow(row)

response = make_response(output.getvalue())
response.headers['Content-Type'] = 'text/csv'
```

### 4. Dashboard analytics
**Agr√©gations**:
- Count total (Elasticsearch count)
- Range query (today)
- Terms aggregation (by level)
- Date histogram (time series)

**Code**:
```python
agg_body = {
    "size": 0,
    "aggs": {
        "by_level": {
            "terms": {"field": "Level"}
        },
        "by_day": {
            "date_histogram": {"field": "@timestamp", "interval": "day"}
        }
    }
}
```

---

## üîê S√©curit√©

### Mesures impl√©ment√©es
- ‚úÖ `secure_filename()` pour uploads
- ‚úÖ Validation taille fichiers
- ‚úÖ Validation extensions
- ‚úÖ CORS configur√©
- ‚úÖ Sanitization des inputs
- ‚úÖ Error handling complet

### Bonnes pratiques
```python
# Validation fichier
if not allowed_file(filename):
    return jsonify({'error': 'File type not allowed'}), 400

# Limite taille
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024

# Secure filename
filename = secure_filename(file.filename)
```

---

## üêõ Debugging

### Activer logs d√©taill√©s
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

### Logs par service
```python
print(f"[OK] Connected to MongoDB")
print(f"[ERROR] Redis connection error: {e}")
```

### Test connexions
```python
# MongoDB
mongo_client.server_info()

# Redis
redis_client.ping()

# Elasticsearch
es_client.info()
```

---

## üöÄ D√©ploiement

### Production avec Gunicorn
```bash
gunicorn -w 4 -b 0.0.0.0:8000 app:app
```

### Docker
```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["gunicorn", "-w", "4", "-b", "0.0.0.0:8000", "app:app"]
```

### Nginx Reverse Proxy
```nginx
location /api/ {
    proxy_pass http://localhost:8000/api/;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
}
```

---

## üìä Performance

### Optimisations
- ‚úÖ Connection pooling (MongoDB, Redis)
- ‚úÖ Bulk indexing Elasticsearch
- ‚úÖ Cache Redis pour requ√™tes fr√©quentes
- ‚úÖ Pagination pour gros r√©sultats
- ‚úÖ Async I/O pour uploads

### Benchmarks
- Upload 1MB CSV: ~2s
- Search query: ~100ms
- Dashboard load: ~300ms
- Export CSV (10k rows): ~5s

---

## üìù Scripts utiles

```bash
# Indexer tous les fichiers data/
python index_all_data_files.py

# Charger logs CSV
python load_sample_logs.py

# Charger events JSON
python load_json_logs.py

# Cr√©er visualisations Kibana
python create_kibana_visualizations.py
```

---

## ü§ù Contribution

### Workflow
1. Fork le repo
2. Cr√©er branche feature
3. D√©velopper + tests
4. Pull request

### Conventions
- **Code style**: PEP 8
- **Docstrings**: Google style
- **Tests**: pytest

---

## üìû Support

Pour toute question:
- üìß Email: backend@ecommerce-analytics.com
- üìñ Documentation API: `BACKEND_API_DOCS.md`

---

**Version**: 1.0.0  
**Derni√®re mise √† jour**: D√©cembre 2025  
**Auteur**: √âquipe E-Commerce Analytics
