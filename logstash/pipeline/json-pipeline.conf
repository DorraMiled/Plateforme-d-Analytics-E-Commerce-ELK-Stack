# JSON Pipeline - Parse e-commerce JSON events
input {
  file {
    path => "/data/ecommerce-events.json"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => "json"
    type => "json_events"
  }
}

filter {
  if [type] == "json_events" {
    # Parse JSON (already handled by codec)
    
    # Parse timestamp
    date {
      match => ["timestamp", "ISO8601", "yyyy-MM-dd'T'HH:mm:ss'Z'"]
      target => "@timestamp"
    }
    
    # Convert numeric fields if present
    if [quantity] {
      mutate {
        convert => {
          "quantity" => "integer"
        }
      }
    }
    
    if [unit_price] {
      mutate {
        convert => {
          "unit_price" => "float"
        }
      }
    }
    
    if [total_amount] {
      mutate {
        convert => {
          "total_amount" => "float"
        }
      }
    }
    
    # Add tags based on event type
    mutate {
      add_tag => ["json", "events", "ecommerce"]
    }
    
    # Add tags based on event type
    if [event_type] == "order_placed" {
      mutate {
        add_tag => ["order"]
      }
    } else if [event_type] == "cart_abandoned" {
      mutate {
        add_tag => ["abandoned_cart"]
      }
    } else if [event_type] == "product_view" {
      mutate {
        add_tag => ["product_view"]
      }
    }
    
    # Parse IP address for geolocation
    if [customer_ip] {
      geoip {
        source => "customer_ip"
        target => "geoip"
      }
    }
    
    # Clean up unwanted fields
    mutate {
      remove_field => ["host", "path"]
    }
  }
}

output {
  if [type] == "json_events" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "ecommerce-logs-%{+YYYY.MM.dd}"
      document_type => "_doc"
    }
    
    stdout {
      codec => rubydebug {
        metadata => false
      }
    }
  }
}
